{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming that our Jupyter Notebook is a driver program\n",
    "from pyspark import SparkContext, StorageLevel\n",
    "from pyspark.sql import SparkSession, functions\n",
    "from pyspark.sql.functions import udf, array, lit\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import json\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "#Start the Spark context\n",
    "sc = SparkContext(\"local[4]\", \"Jumble\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+--------------------+\n",
      "|          word|frequency|          characters|\n",
      "+--------------+---------+--------------------+\n",
      "|     biennials|        0|[a, b, e, i, i, l...|\n",
      "|    tripolitan|        0|[a, i, i, l, n, o...|\n",
      "|     oblocutor|        0|[b, c, l, o, o, o...|\n",
      "|  leucosyenite|        0|[c, e, e, e, i, l...|\n",
      "|      chilitis|        0|[c, h, i, i, i, l...|\n",
      "|     fabianist|        0|[a, a, b, f, i, i...|\n",
      "|     diazeutic|        0|[a, c, d, e, i, i...|\n",
      "|        alible|        0|  [a, b, e, i, l, l]|\n",
      "|         woods|     4601|     [d, o, o, s, w]|\n",
      "|preadjournment|        0|[a, d, e, e, j, m...|\n",
      "|       spiders|        0|[d, e, i, p, r, s...|\n",
      "|     fabianism|        0|[a, a, b, f, i, i...|\n",
      "|   outscolding|        0|[c, d, g, i, l, n...|\n",
      "|    sperrylite|        0|[e, e, i, l, p, r...|\n",
      "|      trawling|        0|[a, g, i, l, n, r...|\n",
      "| cardiospermum|        0|[a, c, d, e, i, m...|\n",
      "|    lighttight|        0|[g, g, h, h, i, i...|\n",
      "|       spidery|        0|[d, e, i, p, r, s...|\n",
      "|    regularize|        0|[a, e, e, g, i, l...|\n",
      "|      beadsmen|        0|[a, b, d, e, e, m...|\n",
      "+--------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load our dictionary into a Spark dataframe\n",
    "with open('freq_dict.json') as json_file:  \n",
    "    frequency_dictionary = json.load(json_file)\n",
    "\n",
    "df = sc.parallelize(frequency_dictionary.items()).toDF(['word', 'frequency'])\n",
    "\n",
    "#Create a dictionary of words and their sorted characters to match\n",
    "character_sort_udf = udf(lambda word: sorted(word), ArrayType(StringType()))\n",
    "df_sorted_characters = df.withColumn(\"characters\", character_sort_udf(df.word))\n",
    "\n",
    "#Persist data as the primary lookup table\n",
    "df_sorted_characters.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "df_sorted_characters.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple lookup against our dictionary to return words that have the same charater sequences, given a sorted sequence\n",
    "def find_words(query):\n",
    "    return df_sorted_characters.where(df_sorted_characters.characters == query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a string or an array of characters, return the character jumble from the given positions\n",
    "def get_character_jumble(row, positions):\n",
    "    jumble_characters = [row[position] for position in positions]\n",
    "    return sorted(jumble_characters)\n",
    "get_character_jumble_udf = udf(get_character_jumble, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper filter function based on count characters\n",
    "def character_subset(row, query):\n",
    "    counter_row = Counter(row)\n",
    "    counter_query = Counter(query)\n",
    "    counter_query.subtract(counter_row)\n",
    "    return not any(char < 0 for char in dict(counter_query).values())\n",
    "is_character_subset_udf = udf(character_subset,BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "puzzle5.json\n",
      "+------------------------------------------+\n",
      "|final_character_jumble                    |\n",
      "+------------------------------------------+\n",
      "|[d, e, e, e, e, g, n, r, s, s, t, t, t, v]|\n",
      "|[d, e, e, e, i, l, n, r, s, s, t, t, t, v]|\n",
      "|[d, e, e, e, e, i, n, s, s, t, t, t, v, y]|\n",
      "|[d, e, e, e, g, l, n, r, s, s, t, t, t, v]|\n",
      "|[d, e, e, e, e, i, n, r, s, s, t, t, t, v]|\n",
      "|[d, e, e, e, i, l, n, s, s, t, t, t, v, y]|\n",
      "+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Iterate over the inputs\n",
    "file_inputs = ['puzzle5.json'\\\n",
    "               ,'puzzle4.json'\\\n",
    "               ,'puzzle3.json'\\\n",
    "               ,'puzzle2.json'\\\n",
    "               ,'puzzle1.json'\\\n",
    "              ]\n",
    "for file in file_inputs:\n",
    "    print(file)\n",
    "    with open(file) as json_file:\n",
    "        puzzle = json.load(json_file)\n",
    "    df_words = None\n",
    "    #Figure out which characters we need from the input data\n",
    "    character_positions = []\n",
    "    offset = 0\n",
    "    #Find possible answers to 1-word scrambles, then join to form combinations of the n 1-word scramble\n",
    "    for key, value in puzzle[0].items():\n",
    "        character_positions.extend(x+offset for x in value)\n",
    "        if df_words is None:\n",
    "            df_words = find_words(array(*(lit(x) for x in sorted(key))))\n",
    "            df_words = df_words.select(df_sorted_characters.word.alias(\"word_merged\"),\\\n",
    "                                       df_sorted_characters.frequency.alias(\"frequency_merged\"),\\\n",
    "                                       df_sorted_characters.characters.alias(\"characters_merged\"))\n",
    "        else:\n",
    "            df_words = df_words.crossJoin(find_words(array(*(lit(x) for x in sorted(key)))))\n",
    "            df_words = df_words.select(functions.concat(df_words.word_merged, df_words.word).alias(\"word_merged\"),\\\n",
    "                                      functions.concat(df_words.frequency_merged, lit(\" \"), df_words.frequency).alias(\"frequency_merged\"),\\\n",
    "                                      functions.concat(df_words.characters_merged, df_words.characters).alias(\"characters_merged\"))\n",
    "        offset = offset + len(key)\n",
    "    #Find character combinations for n 1-words\n",
    "    df_words = df_words.select(get_character_jumble_udf(df_words.word_merged, array([lit(x) for x in character_positions])).alias(\"final_character_jumble\")).distinct()\n",
    "    df_words.show(20,False)\n",
    "\n",
    "    #Find possible answers to successive words in the final scramble\n",
    "    df_final_jumble = None\n",
    "    for word_length in puzzle[1]:\n",
    "        if df_final_jumble is None:\n",
    "            df_final_jumble = df_words.crossJoin(df_sorted_characters.where(functions.length(df_sorted_characters.word) == word_length))\\\n",
    "            .filter(is_character_subset_udf(df_sorted_characters.characters, df_words.final_character_jumble))\\\n",
    "            .select(df_words.final_character_jumble,\\\n",
    "                    df_sorted_characters.word.alias(\"word_merged\"),\\\n",
    "                    df_sorted_characters.frequency.alias(\"frequency_merged\"),\\\n",
    "                    df_sorted_characters.characters.alias(\"characters_merged\"))\n",
    "        else:\n",
    "            df_final_jumble = df_final_jumble.crossJoin(df_sorted_characters.where(functions.length(df_sorted_characters.word) == word_length))\\\n",
    "            .filter(is_character_subset_udf(df_sorted_characters.characters, df_final_jumble.final_character_jumble))\\\n",
    "            .select(df_final_jumble.final_character_jumble,\\\n",
    "                    functions.concat(df_final_jumble.word_merged, lit(\" \"), df_sorted_characters.word).alias(\"word_merged\"),\\\n",
    "                    (df_final_jumble.frequency_merged + df_sorted_characters.frequency).alias(\"frequency_merged\"),\\\n",
    "                    functions.sort_array(functions.concat(df_final_jumble.characters_merged, df_sorted_characters.characters)).alias(\"characters_merged\")\\\n",
    "                   ).filter(is_character_subset_udf(df_final_jumble.characters_merged, df_final_jumble.final_character_jumble))\n",
    "\n",
    "    #Implemented algo for threshold greater than 600\n",
    "    df_final_jumble.where(df_final_jumble.final_character_jumble == df_final_jumble.characters_merged).where(df_final_jumble.frequency_merged > 600).sort(\"frequency_merged\").limit(1).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
